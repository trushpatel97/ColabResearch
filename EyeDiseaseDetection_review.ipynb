{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EyeDiseaseDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vZYRKX1eMrHc",
        "nIv-MOUc4qN0",
        "0ONqLEa07c4O",
        "IUFRsr1y72fc",
        "kZSAdFr_7_F4",
        "Eodg8nrd8KvR",
        "RWxhKovW8f8J",
        "YJDDpEdv_vIw",
        "MbFUdEN_8Ypv",
        "CURx1X198q0A"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trushpatel97/ColabResearch/blob/master/EyeDiseaseDetection_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRY9gfJjoMi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "7aa0712a-3699-410c-9d78-93d7b4d73ce3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw_rFfNu3iUS",
        "colab_type": "text"
      },
      "source": [
        "# **Eye Disease Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0ks8VhK3092",
        "colab_type": "text"
      },
      "source": [
        "**Steps taken to solve problem**\n",
        "* Step 1: Import common libraries\n",
        "* Step 2: Setup GPU\n",
        "* Step 3: Getting the data\n",
        "* Step 4: Build/Train a CNN\n",
        "* Step 5: Fit the data\n",
        "* Step 6: Improve the model\n",
        "* Step 7: Fit improved model\n",
        "* Step 8: Save the model\n",
        "* Step 9: Presenting results visually\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZYRKX1eMrHc",
        "colab_type": "text"
      },
      "source": [
        "## **Global variables/Hyperparameters**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05pVTzhNMxBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image_height = 224\n",
        "Image_width = 224\n",
        "val_split = 0.20\n",
        "batches_size = 16\n",
        "lr = 0.0005\n",
        "spe = 220\n",
        "vs = 32\n",
        "epoch = 6"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIv-MOUc4qN0",
        "colab_type": "text"
      },
      "source": [
        "## **Step 1: Import common libraries**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB-NfE9p3hWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Common machine learning libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "#Used for setting up GPU and image classifcation\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub \n",
        "\n",
        "#Used for seeing how many images we have within each folder\n",
        "import os\n",
        "\n",
        "#Used for split / viewing images later on\n",
        "import glob\n",
        "\n",
        "#Libraries needed for image classification\n",
        "from tensorflow import keras \n",
        "from keras.optimizers import Adam,Adamax\n",
        "from tensorflow.python.keras.layers import Input, Activation, Conv2D, MaxPool2D,MaxPooling2D, BatchNormalization, UpSampling2D, Lambda\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications import imagenet_utils\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ONqLEa07c4O",
        "colab_type": "text"
      },
      "source": [
        "## **Step 2: Setup GPU**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4qobbQc5bvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a767b9ea-fa11-4b93-edac-9e78edec1d1a"
      },
      "source": [
        "print(\"GPU is working\" if tf.config.list_physical_devices(\"GPU\") else \" GPU is not working. Please change the runtime to use GPU\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is working\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUFRsr1y72fc",
        "colab_type": "text"
      },
      "source": [
        "## **Step 3: Getting Data**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mmb5rQU79IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the file of the training set and testing set\n",
        "train_folder = \"/content/drive/My Drive/Research/train\"\n",
        "test_folder = \"/content/drive/My Drive/Research/test\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWbEAsdE_j4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "8ed1f3d4-fea5-4cad-a097-f445efee78b7"
      },
      "source": [
        "#Code to iterate over all the files (Sub directories included). This will be used to see how many training and images we have\n",
        "CNV_train = os.listdir(\"/content/drive/My Drive/Research/train/CNV\")\n",
        "DME_train = os.listdir(\"/content/drive/My Drive/Research/train/DME\")\n",
        "DRUSEN_train = os.listdir(\"/content/drive/My Drive/Research/train/DRUSEN\")\n",
        "NORMAL_train = os.listdir(\"/content/drive/My Drive/Research/train/NORMAL\")\n",
        "\n",
        "CNV_test = os.listdir(\"/content/drive/My Drive/Research/test/CNV\") \n",
        "DME_test = os.listdir(\"/content/drive/My Drive/Research/test/DME\")\n",
        "DRUSEN_test = os.listdir(\"/content/drive/My Drive/Research/test/DRUSEN\")\n",
        "NORMAL_test = os.listdir(\"/content/drive/My Drive/Research/test/NORMAL\")\n",
        "\n",
        "total_training = len(CNV_train + DME_train + DRUSEN_train + NORMAL_train)\n",
        "total_testing = len(CNV_test + DME_test + DRUSEN_test + NORMAL_test)\n",
        "\n",
        "print(\"We have\",total_training, \"total images in the training folder and\", total_testing, \"images in the testing folder\")\n",
        "print(f\"Allocating {(1-val_split)*100}% for training {val_split*100}% for validation on the training set we get:\")\n",
        "print(total_training*(1-val_split), \"images for training\")\n",
        "print(total_training*(val_split), \"images for validation\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 83484 total images in the training folder and 1000 images in the testing folder\n",
            "Allocating 80.0% for training 20.0% for validation on the training set we get:\n",
            "66787.2 images for training\n",
            "16696.8 images for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQCGevjaGZQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e04846d1-2905-452f-dcb4-850f912c4073"
      },
      "source": [
        "#Creating batches\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,validation_split=val_split) \\\n",
        "    .flow_from_directory(directory=train_folder, target_size=(Image_height,Image_width), classes=['CNV','DME','DRUSEN','NORMAL'], batch_size=batches_size,class_mode=\"categorical\",\n",
        "                              subset=\"training\")\n",
        "validation_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,validation_split=val_split) \\\n",
        "    .flow_from_directory(directory=train_folder, target_size=(Image_height,Image_width), classes=['CNV','DME','DRUSEN','NORMAL'], batch_size=batches_size,class_mode=\"categorical\",\n",
        "                              subset=\"validation\")\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input) \\\n",
        "                       .flow_from_directory(test_folder, target_size=(Image_height,Image_width), \n",
        "                         classes=['CNV','DME','DRUSEN','NORMAL'], batch_size=batches_size,class_mode=\"categorical\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 66788 images belonging to 4 classes.\n",
            "Found 16696 images belonging to 4 classes.\n",
            "Found 1000 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZSAdFr_7_F4",
        "colab_type": "text"
      },
      "source": [
        "## **Step 4: Build/Train a CNN**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buo55eOK8GHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building the model to train a CNN. This will be used to extract features of images\n",
        "model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(Image_height,Image_width,3)),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Flatten(),\n",
        "    Dense(units=4, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe_ATN6HmKf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "547f9333-c8e7-477f-b8c4-8e72a3e9b587"
      },
      "source": [
        "#Checking the models summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 194, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 149, 97, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 147, 95, 64)       18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 47, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 219584)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 878340    \n",
            "=================================================================\n",
            "Total params: 897,732\n",
            "Trainable params: 897,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eodg8nrd8KvR",
        "colab_type": "text"
      },
      "source": [
        "## **Step 5: Fit the data**\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNcqC9G8N7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compiling the model\n",
        "model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHg3k3Xrm-Sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "479513c1-6aa3-4bd8-c73f-9fa875050f9f"
      },
      "source": [
        "#Fitting the data\n",
        "model.fit(train_batches, steps_per_epoch = spe, epochs = epoch, \n",
        "            validation_data = vs, validation_steps = vs,shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "128/128 [==============================] - 1893s 15s/step - loss: 6.1900 - accuracy: 0.4561 - val_loss: 3.1588 - val_accuracy: 0.4326\n",
            "Epoch 2/10\n",
            "128/128 [==============================] - 1604s 13s/step - loss: 1.9485 - accuracy: 0.5793 - val_loss: 1.3147 - val_accuracy: 0.6201\n",
            "Epoch 3/10\n",
            "128/128 [==============================] - 1464s 11s/step - loss: 1.0720 - accuracy: 0.6740 - val_loss: 1.1694 - val_accuracy: 0.6445\n",
            "Epoch 4/10\n",
            "128/128 [==============================] - 1444s 11s/step - loss: 0.9682 - accuracy: 0.6892 - val_loss: 0.9238 - val_accuracy: 0.6865\n",
            "Epoch 5/10\n",
            "128/128 [==============================] - 1289s 10s/step - loss: 0.7701 - accuracy: 0.7217 - val_loss: 0.8793 - val_accuracy: 0.7012\n",
            "Epoch 6/10\n",
            "128/128 [==============================] - 1331s 10s/step - loss: 0.6729 - accuracy: 0.7637 - val_loss: 0.7865 - val_accuracy: 0.7178\n",
            "Epoch 7/10\n",
            "128/128 [==============================] - 1155s 9s/step - loss: 0.6316 - accuracy: 0.7793 - val_loss: 0.7348 - val_accuracy: 0.7383\n",
            "Epoch 8/10\n",
            "128/128 [==============================] - 1089s 9s/step - loss: 0.5662 - accuracy: 0.7991 - val_loss: 0.6929 - val_accuracy: 0.7520\n",
            "Epoch 9/10\n",
            "128/128 [==============================] - 1030s 8s/step - loss: 0.5703 - accuracy: 0.8057 - val_loss: 0.7513 - val_accuracy: 0.7324\n",
            "Epoch 10/10\n",
            "128/128 [==============================] - 936s 7s/step - loss: 0.4924 - accuracy: 0.8274 - val_loss: 0.7007 - val_accuracy: 0.7451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c380d6c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKxmA6yQwenD",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v22ahOd9wpwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"CNN.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_8H7cYfwxqJ",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Improve the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjJABj3fuuBZ",
        "colab_type": "text"
      },
      "source": [
        "### VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k3zpaETvU5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to create model. We will be using a pretrained model\n",
        "def create():\n",
        "  vgg16_model = keras.applications.vgg16.VGG16(input_tensor=Input(shape=(Image_height, Image_width, 3)),input_shape=(Image_height,Image_width,3), include_top = False)\n",
        "  model = Sequential()\n",
        "  model.add(vgg16_model)\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y4eMejNvJf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.create()\n",
        "model.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHpSxmQvFUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches_10,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j3k1Yaf8nCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"VGG16_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnlB5DiDq3ge",
        "colab_type": "text"
      },
      "source": [
        "### Xception Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3mqyjP1HQBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create():\n",
        "  xception_model = tf.keras.applications.Xception(input_tensor=Input(shape=(Image_height, Image_width, 3)),input_shape=(Image_height,Image_width,3), include_top = False)\n",
        "  model = Sequential()\n",
        "  model.add(xception_model)\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzIAXDsLPCgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b0f03f34-4860-4e65-ca3c-571466c6d543"
      },
      "source": [
        "model = create()\n",
        "model.compile(Adam(lr=lr),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_5_lqAdPHFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f433426c-daab-47c1-afb1-ba4a33105da4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 6, 10, 2048)       20861480  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 122880)            0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 491524    \n",
            "=================================================================\n",
            "Total params: 21,353,004\n",
            "Trainable params: 491,524\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_knHbi9PKgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7c4e32b9-e3be-43f1-be57-6ff5ce213567"
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "512/512 [==============================] - 5606s 11s/step - loss: 7.4320 - accuracy: 0.5426 - val_loss: 8.0523 - val_accuracy: 0.4859\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5079s 10s/step - loss: 6.7518 - accuracy: 0.5625 - val_loss: 7.8662 - val_accuracy: 0.6047\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4459s 9s/step - loss: 7.1621 - accuracy: 0.5709 - val_loss: 8.9813 - val_accuracy: 0.5594\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4002s 8s/step - loss: 7.1249 - accuracy: 0.5852 - val_loss: 10.5663 - val_accuracy: 0.5512\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 3659s 7s/step - loss: 7.0733 - accuracy: 0.5764 - val_loss: 8.5909 - val_accuracy: 0.5840\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - ETA: 0s - loss: 6.5823 - accuracy: 0.6037"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INGRIXs1vwZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Xception.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqmxsIYPY90f",
        "colab_type": "text"
      },
      "source": [
        "### MobileNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjQiv6GDZGD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobile = tf.keras.applications.mobilenet.MobileNet(include_top=False,\n",
        "                                                           input_shape=(224, 224,3),\n",
        "                                                           pooling='max', weights='imagenet',\n",
        "                                                           alpha=1, depth_multiplier=1,dropout=.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CFZlf-JUORM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=mobile.layers[-1].output\n",
        "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
        "predictions=Dense (4, activation='softmax')(x)\n",
        "model = Model(inputs=mobile.input, outputs=predictions)    \n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "model.compile(Adamax(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/My Drive/Research/ModelCheckpoint\", monitor='val_loss', verbose=0, save_best_only=True,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch', options=None)\n",
        "lr_adjust=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=1, verbose=0, mode=\"auto\",\n",
        "    min_delta=0.00001,  cooldown=0,  min_lr=0) \n",
        "callbacks=[checkpoint, lr_adjust]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db_G7RygV7Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVsjpGRwwKCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Mobilenet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcBH4jxVX7mZ",
        "colab_type": "text"
      },
      "source": [
        "## Step 8: Improve MobileNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB4v99EuYSac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobile = tf.keras.applications.mobilenet.MobileNet(include_top=False,\n",
        "                                                           input_shape=(224, 224,3),\n",
        "                                                           pooling='max', weights='imagenet',\n",
        "                                                           alpha=1, depth_multiplier=1,dropout=.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdHXJYJ_kJfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=mobile.layers[-1].output\n",
        "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
        "predictions=Dense (4, activation='softmax')(x)\n",
        "model = Model(inputs=mobile.input, outputs=predictions)    \n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "model.compile(Adamax(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/My Drive/Research/ModelCheckpoint\", monitor='val_loss', verbose=0, save_best_only=True,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch', options=None)\n",
        "lr_adjust=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=1, verbose=0, mode=\"auto\",\n",
        "    min_delta=0.00001,  cooldown=0,  min_lr=0) \n",
        "callbacks=[checkpoint, lr_adjust]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlNYe5ikNcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cdb8db48-562a-4411-a880-9b793af43957"
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "220/220 [==============================] - 2952s 13s/step - loss: 0.5842 - accuracy: 0.7912 - val_loss: 0.7926 - val_accuracy: 0.7988\n",
            "Epoch 2/6\n",
            "220/220 [==============================] - 2736s 12s/step - loss: 0.4041 - accuracy: 0.8723 - val_loss: 0.3094 - val_accuracy: 0.9023\n",
            "Epoch 3/6\n",
            "220/220 [==============================] - 2635s 12s/step - loss: 0.3718 - accuracy: 0.8804 - val_loss: 0.3871 - val_accuracy: 0.8906\n",
            "Epoch 4/6\n",
            "220/220 [==============================] - 2517s 11s/step - loss: 0.2904 - accuracy: 0.8980 - val_loss: 0.2863 - val_accuracy: 0.9160\n",
            "Epoch 5/6\n",
            "220/220 [==============================] - 2364s 11s/step - loss: 0.2779 - accuracy: 0.9057 - val_loss: 0.3500 - val_accuracy: 0.9238\n",
            "Epoch 6/6\n",
            "220/220 [==============================] - 2241s 10s/step - loss: 0.2839 - accuracy: 0.9068 - val_loss: 0.2202 - val_accuracy: 0.9355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f8a59eb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax47fyT---7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Mobilenet_v2.h5\")#(Size of batches 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CURx1X198q0A",
        "colab_type": "text"
      },
      "source": [
        "## **Step 9: Testing results**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pACj5dL8u2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load model if needed\n",
        "model = keras.models.load_model('/content/Mobilenet_v2.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75AZoH3vEuIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adamax', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Ky7-NDuuet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aaded64f-cf26-4813-a758-a6d25620d84a"
      },
      "source": [
        "test_folder = \"/content/drive/My Drive/Research/test\"\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input) \\\n",
        "                       .flow_from_directory(test_folder, target_size=(Image_height,Image_width), \n",
        "                         classes=['CNV','DME','DRUSEN','NORMAL'], batch_size=batches_size,class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T7p_AqDejH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x=test_batches,verbose=0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T07IBcV6er04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "47371c21-6b2c-4a5c-9d59-4abed0d6ad55"
      },
      "source": [
        "np.round(predictions)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05nLs_TkA1Tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "966eaddf-78cc-46f3-8e8c-1357fb03465b"
      },
      "source": [
        "# Predict the accuracy on the Test set\n",
        "acc = model.evaluate_generator(test_batches, steps=len(test_batches), verbose=1)\n",
        "print(\"Model Accuracy on Test Data\", acc[1]*100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1519 - accuracy: 0.9410\n",
            "Model Accuracy on Test Data 94.0999984741211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKzaOXMqu14y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "9a3f6eda-98fa-46aa-a183-1632957fdaa7"
      },
      "source": [
        "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "cm_plot_labels = ['CNV','DME','DRUSEN','NORMAL']\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[78 61 51 60]\n",
            " [73 62 53 62]\n",
            " [67 72 49 62]\n",
            " [85 57 42 66]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B07RpEQdv-17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}