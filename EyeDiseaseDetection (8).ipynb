{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EyeDiseaseDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vZYRKX1eMrHc",
        "nIv-MOUc4qN0",
        "0ONqLEa07c4O",
        "IUFRsr1y72fc",
        "kZSAdFr_7_F4",
        "Eodg8nrd8KvR",
        "RWxhKovW8f8J",
        "YJDDpEdv_vIw",
        "MbFUdEN_8Ypv",
        "CURx1X198q0A"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRY9gfJjoMi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ea50748f-3711-429f-b880-aba8b7a75894"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw_rFfNu3iUS",
        "colab_type": "text"
      },
      "source": [
        "# **Eye Disease Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0ks8VhK3092",
        "colab_type": "text"
      },
      "source": [
        "**Steps taken to solve problem**\n",
        "* Step 1: Import common libraries\n",
        "* Step 2: Setup GPU\n",
        "* Step 3: Getting the data\n",
        "* Step 4: Build/Train a CNN\n",
        "* Step 5: Fit the data\n",
        "* Step 6: Improve the model\n",
        "* Step 7: Fit improved model\n",
        "* Step 8: Save the model\n",
        "* Step 9: Presenting results visually\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZYRKX1eMrHc",
        "colab_type": "text"
      },
      "source": [
        "## **Global variables/Hyperparameters**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05pVTzhNMxBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image_height = 196\n",
        "Image_width = 300\n",
        "val_split = 0.2\n",
        "batches_size = 5\n",
        "lr = 0.0001\n",
        "spe = 512\n",
        "vs = 32\n",
        "epoch = 10"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIv-MOUc4qN0",
        "colab_type": "text"
      },
      "source": [
        "## **Step 1: Import common libraries**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB-NfE9p3hWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Common machine learning libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "#Used for setting up GPU and image classifcation\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub \n",
        "\n",
        "#Used for seeing how many images we have within each folder\n",
        "import os\n",
        "\n",
        "#Used for split / viewing images later on\n",
        "import glob\n",
        "\n",
        "#Libraries needed for image classification\n",
        "from tensorflow import keras \n",
        "from keras.optimizers import Adam,Adamax\n",
        "from tensorflow.python.keras.layers import Input, Activation, Conv2D, MaxPool2D,MaxPooling2D, BatchNormalization, UpSampling2D, Lambda\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications import imagenet_utils\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ONqLEa07c4O",
        "colab_type": "text"
      },
      "source": [
        "## **Step 2: Setup GPU**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4qobbQc5bvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c28f06dc-708c-4b85-ffd8-2b8393b33f08"
      },
      "source": [
        "print(\"GPU is working\" if tf.config.list_physical_devices(\"GPU\") else \" GPU is not working. Please change the runtime to use GPU\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is working\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUFRsr1y72fc",
        "colab_type": "text"
      },
      "source": [
        "## **Step 3: Getting Data**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mmb5rQU79IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the file of the training set and testing set\n",
        "train_folder = \"/content/drive/My Drive/Research/train\"\n",
        "test_folder = \"/content/drive/My Drive/Research/test\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWbEAsdE_j4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to iterate over all the files (Sub directories included). This will be used to see how many training and images we have\n",
        "CNV_train = os.listdir(\"/content/drive/My Drive/Research/train/CNV\")\n",
        "DME_train = os.listdir(\"/content/drive/My Drive/Research/train/DME\")\n",
        "DRUSEN_train = os.listdir(\"/content/drive/My Drive/Research/train/DRUSEN\")\n",
        "NORMAL_train = os.listdir(\"/content/drive/My Drive/Research/train/NORMAL\")\n",
        "\n",
        "CNV_test = os.listdir(\"/content/drive/My Drive/Research/test/CNV\") \n",
        "DME_test = os.listdir(\"/content/drive/My Drive/Research/test/DME\")\n",
        "DRUSEN_test = os.listdir(\"/content/drive/My Drive/Research/test/DRUSEN\")\n",
        "NORMAL_test = os.listdir(\"/content/drive/My Drive/Research/test/NORMAL\")\n",
        "\n",
        "total_training = len(CNV_train + DME_train + DRUSEN_train + NORMAL_train)\n",
        "total_testing = len(CNV_test + DME_test + DRUSEN_test + NORMAL_test)\n",
        "\n",
        "print(\"We have\",total_training, \"total images in the training folder and\", total_testing, \"images in the testing folder\")\n",
        "print(f\"Allocating {(1-val_split)*100}% for training {val_split*100}% for validation on the training set we get:\")\n",
        "print(total_training*(1-val_split), \"images for training\")\n",
        "print(total_training*(val_split), \"images for validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQCGevjaGZQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d509138e-62d8-41b6-f481-34ea63bf7aac"
      },
      "source": [
        "#Creating batches\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,validation_split=val_split) \\\n",
        "    .flow_from_directory(directory=train_folder, target_size=(224,224), classes=['CNV','DME','DRUSEN','NORMAL'], batch_size=batches_size,class_mode=\"categorical\",\n",
        "                              subset=\"training\")\n",
        "validation_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,validation_split=val_split) \\\n",
        "    .flow_from_directory(directory=train_folder, target_size=(224,224), classes=['CNV','DME','DRUSEN','NORMAL'], batch_size=batches_size,class_mode=\"categorical\",\n",
        "                              subset=\"validation\")\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input) \\\n",
        "                       .flow_from_directory(test_folder, target_size=(224,224), \n",
        "                         classes=['CNV','DME','DRUSEN','NORMAL'], batch_size=batches_size,class_mode=\"categorical\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 66788 images belonging to 4 classes.\n",
            "Found 16696 images belonging to 4 classes.\n",
            "Found 1000 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZSAdFr_7_F4",
        "colab_type": "text"
      },
      "source": [
        "## **Step 4: Build/Train a CNN**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buo55eOK8GHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building the model to train a CNN. This will be used to extract features of images\n",
        "model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(Image_height,Image_width,3)),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Flatten(),\n",
        "    Dense(units=4, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe_ATN6HmKf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "547f9333-c8e7-477f-b8c4-8e72a3e9b587"
      },
      "source": [
        "#Checking the models summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 194, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 149, 97, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 147, 95, 64)       18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 47, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 219584)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 878340    \n",
            "=================================================================\n",
            "Total params: 897,732\n",
            "Trainable params: 897,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eodg8nrd8KvR",
        "colab_type": "text"
      },
      "source": [
        "## **Step 5: Fit the data**\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNcqC9G8N7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compiling the model\n",
        "model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHg3k3Xrm-Sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "479513c1-6aa3-4bd8-c73f-9fa875050f9f"
      },
      "source": [
        "#Fitting the data\n",
        "model.fit(train_batches, steps_per_epoch = spe, epochs = epoch, \n",
        "            validation_data = vs, validation_steps = vs,shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "128/128 [==============================] - 1893s 15s/step - loss: 6.1900 - accuracy: 0.4561 - val_loss: 3.1588 - val_accuracy: 0.4326\n",
            "Epoch 2/10\n",
            "128/128 [==============================] - 1604s 13s/step - loss: 1.9485 - accuracy: 0.5793 - val_loss: 1.3147 - val_accuracy: 0.6201\n",
            "Epoch 3/10\n",
            "128/128 [==============================] - 1464s 11s/step - loss: 1.0720 - accuracy: 0.6740 - val_loss: 1.1694 - val_accuracy: 0.6445\n",
            "Epoch 4/10\n",
            "128/128 [==============================] - 1444s 11s/step - loss: 0.9682 - accuracy: 0.6892 - val_loss: 0.9238 - val_accuracy: 0.6865\n",
            "Epoch 5/10\n",
            "128/128 [==============================] - 1289s 10s/step - loss: 0.7701 - accuracy: 0.7217 - val_loss: 0.8793 - val_accuracy: 0.7012\n",
            "Epoch 6/10\n",
            "128/128 [==============================] - 1331s 10s/step - loss: 0.6729 - accuracy: 0.7637 - val_loss: 0.7865 - val_accuracy: 0.7178\n",
            "Epoch 7/10\n",
            "128/128 [==============================] - 1155s 9s/step - loss: 0.6316 - accuracy: 0.7793 - val_loss: 0.7348 - val_accuracy: 0.7383\n",
            "Epoch 8/10\n",
            "128/128 [==============================] - 1089s 9s/step - loss: 0.5662 - accuracy: 0.7991 - val_loss: 0.6929 - val_accuracy: 0.7520\n",
            "Epoch 9/10\n",
            "128/128 [==============================] - 1030s 8s/step - loss: 0.5703 - accuracy: 0.8057 - val_loss: 0.7513 - val_accuracy: 0.7324\n",
            "Epoch 10/10\n",
            "128/128 [==============================] - 936s 7s/step - loss: 0.4924 - accuracy: 0.8274 - val_loss: 0.7007 - val_accuracy: 0.7451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c380d6c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKxmA6yQwenD",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v22ahOd9wpwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"CNN.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_8H7cYfwxqJ",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Improve the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjJABj3fuuBZ",
        "colab_type": "text"
      },
      "source": [
        "### VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k3zpaETvU5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to create model. We will be using a pretrained model\n",
        "def create():\n",
        "  vgg16_model = keras.applications.vgg16.VGG16(input_tensor=Input(shape=(Image_height, Image_width, 3)),input_shape=(Image_height,Image_width,3), include_top = False)\n",
        "  model = Sequential()\n",
        "  model.add(vgg16_model)\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y4eMejNvJf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.create()\n",
        "model.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHpSxmQvFUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches_10,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j3k1Yaf8nCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"VGG16_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnlB5DiDq3ge",
        "colab_type": "text"
      },
      "source": [
        "### Xception Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3mqyjP1HQBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create():\n",
        "  xception_model = tf.keras.applications.Xception(input_tensor=Input(shape=(Image_height, Image_width, 3)),input_shape=(Image_height,Image_width,3), include_top = False)\n",
        "  model = Sequential()\n",
        "  model.add(xception_model)\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzIAXDsLPCgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b0f03f34-4860-4e65-ca3c-571466c6d543"
      },
      "source": [
        "model = create()\n",
        "model.compile(Adam(lr=lr),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_5_lqAdPHFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f433426c-daab-47c1-afb1-ba4a33105da4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 6, 10, 2048)       20861480  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 122880)            0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 491524    \n",
            "=================================================================\n",
            "Total params: 21,353,004\n",
            "Trainable params: 491,524\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_knHbi9PKgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7c4e32b9-e3be-43f1-be57-6ff5ce213567"
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "512/512 [==============================] - 5606s 11s/step - loss: 7.4320 - accuracy: 0.5426 - val_loss: 8.0523 - val_accuracy: 0.4859\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5079s 10s/step - loss: 6.7518 - accuracy: 0.5625 - val_loss: 7.8662 - val_accuracy: 0.6047\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4459s 9s/step - loss: 7.1621 - accuracy: 0.5709 - val_loss: 8.9813 - val_accuracy: 0.5594\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4002s 8s/step - loss: 7.1249 - accuracy: 0.5852 - val_loss: 10.5663 - val_accuracy: 0.5512\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 3659s 7s/step - loss: 7.0733 - accuracy: 0.5764 - val_loss: 8.5909 - val_accuracy: 0.5840\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - ETA: 0s - loss: 6.5823 - accuracy: 0.6037"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INGRIXs1vwZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Xception.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqmxsIYPY90f",
        "colab_type": "text"
      },
      "source": [
        "### MobileNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjQiv6GDZGD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobile = tf.keras.applications.mobilenet.MobileNet(include_top=False,\n",
        "                                                           input_shape=(224, 224,3),\n",
        "                                                           pooling='max', weights='imagenet',\n",
        "                                                           alpha=1, depth_multiplier=1,dropout=.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CFZlf-JUORM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=mobile.layers[-1].output\n",
        "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
        "predictions=Dense (4, activation='softmax')(x)\n",
        "model = Model(inputs=mobile.input, outputs=predictions)    \n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "model.compile(Adamax(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/My Drive/Research/ModelCheckpoint\", monitor='val_loss', verbose=0, save_best_only=True,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch', options=None)\n",
        "lr_adjust=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=1, verbose=0, mode=\"auto\",\n",
        "    min_delta=0.00001,  cooldown=0,  min_lr=0) \n",
        "callbacks=[checkpoint, lr_adjust]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db_G7RygV7Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVsjpGRwwKCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Mobilenet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcBH4jxVX7mZ",
        "colab_type": "text"
      },
      "source": [
        "## Step 8: Improve MobileNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB4v99EuYSac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobile = tf.keras.applications.mobilenet.MobileNet(include_top=False,\n",
        "                                                           input_shape=(224, 224,3),\n",
        "                                                           pooling='max', weights='imagenet',\n",
        "                                                           alpha=1, depth_multiplier=1,dropout=.5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdHXJYJ_kJfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=mobile.layers[-1].output\n",
        "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
        "predictions=Dense (4, activation='softmax')(x)\n",
        "model = Model(inputs=mobile.input, outputs=predictions)    \n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "model.compile(Adamax(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/My Drive/Research/ModelCheckpoint\", monitor='val_loss', verbose=0, save_best_only=True,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch', options=None)\n",
        "lr_adjust=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=1, verbose=0, mode=\"auto\",\n",
        "    min_delta=0.00001,  cooldown=0,  min_lr=0) \n",
        "callbacks=[checkpoint, lr_adjust]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlNYe5ikNcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "9631b9d4-9408-4019-9607-c4469d3dc5c7"
      },
      "source": [
        "model.fit(train_batches, steps_per_epoch=spe,\n",
        "                    validation_data=validation_batches,validation_steps=vs, epochs=epoch)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "512/512 [==============================] - 738s 1s/step - loss: 1.2648 - accuracy: 0.5082 - val_loss: 0.9452 - val_accuracy: 0.6438\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 676s 1s/step - loss: 0.9054 - accuracy: 0.6617 - val_loss: 0.5828 - val_accuracy: 0.7688\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 629s 1s/step - loss: 0.7676 - accuracy: 0.7258 - val_loss: 0.4696 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 612s 1s/step - loss: 0.7470 - accuracy: 0.7348 - val_loss: 0.4521 - val_accuracy: 0.8375\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 591s 1s/step - loss: 0.7004 - accuracy: 0.7531 - val_loss: 0.5530 - val_accuracy: 0.8313\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 592s 1s/step - loss: 0.6732 - accuracy: 0.7715 - val_loss: 0.4451 - val_accuracy: 0.8813\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 537s 1s/step - loss: 0.6653 - accuracy: 0.7727 - val_loss: 0.2994 - val_accuracy: 0.9312\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 535s 1s/step - loss: 0.6352 - accuracy: 0.7676 - val_loss: 0.4212 - val_accuracy: 0.8687\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 503s 983ms/step - loss: 0.6403 - accuracy: 0.7703 - val_loss: 0.4403 - val_accuracy: 0.8500\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 494s 964ms/step - loss: 0.5971 - accuracy: 0.7879 - val_loss: 0.4269 - val_accuracy: 0.8313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e6e324668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax47fyT---7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Mobilenet_v1.1.h5\")#Half batch size (Size of batches 5)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CURx1X198q0A",
        "colab_type": "text"
      },
      "source": [
        "## **Step 9: Testing results**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pACj5dL8u2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load model if needed\n",
        "model = keras.models.load_model('/content/Mobilenet_v1.1.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD0EMZCeeU-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46fe9b58-b093-43d6-eb9a-45cfe462b442"
      },
      "source": [
        "test_batches.classes[0:1000:100]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 2, 2, 2, 3, 3], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T7p_AqDejH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x=test_batches,verbose=0)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T07IBcV6er04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "aa995c61-a3f5-43bb-9eec-a31ffe588c79"
      },
      "source": [
        "np.round(predictions)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05nLs_TkA1Tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b4a56c91-60ec-4b6c-d318-e06807723a61"
      },
      "source": [
        "# Predict the accuracy on the Test Test!\n",
        "acc = model.evaluate_generator(test_batches, steps=len(test_batches), verbose=1)\n",
        "print(\"Model Accuracy on Test Data\", acc[1]*100)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 6s 29ms/step - loss: 0.2417 - accuracy: 0.9100\n",
            "Model Accuracy on Test Data 91.00000262260437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWUeiEu6Dh34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}